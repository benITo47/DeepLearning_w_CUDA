{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPHdyZXeD4oBWsFH5TRF1OS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#### DEEP LEARNINING WITH CUDA LAB REPORT NO.3\n"],"metadata":{"id":"WnELQzQkPVE4"}},{"cell_type":"markdown","source":["This report will focus on PyTorch library.\n","We'll cover topics such as:\n","  * Tensors\n","  * Building, training and evaluting models\n","  \n"],"metadata":{"id":"XwHJr16KPaLB"}},{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import transforms"],"metadata":{"id":"tyY9P1xLTcxm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tensors\n","At its most basic, a tensor is a mathematical object that generalizes scalars, **vectors**, and matrices to higher dimensions.\n","\n","In the context of PyTorch and machine learning, tensors are essentially multi-dimensional arrays or matrices that are used for storing data.\n","\n","Let's see what tensors are and what can we do with them.\n","\n"],"metadata":{"id":"HzhNgvlFV28k"}},{"cell_type":"markdown","source":["### Creating tensors\n","\n","Tensors can be created in various ways, including from existing data (like Python lists or NumPy arrays) or by using built-in PyTorch functions that generate tensors of specific types.\n","\n"],"metadata":{"id":"y0JiOF1TZpQl"}},{"cell_type":"code","source":["a = torch.tensor([1,2,3,4]) ### Creates a 1x4 tensor\n","b = torch.ones(2,3) ### Creates a 2x3 tensor filled with ones\n","c = torch.rand(2,5) ### Creates a 2x5 tensor filled with random values\n","\n","### We can also create tensors from existing data:\n","\n","d = [[1,2], [3,4]]\n","tensor_d = torch.tensor(d) ### Using matrix a, we can create 2x2 tensor\n","\n","e = np.array([[1,2],[1,2],[3,4],[3,4]])\n","tensor_e = torch.from_numpy(e) ### Using NymPy arrays\n","\n","### We can also specify the data type\n","f = torch.ones(2, 5, dtype=torch.float)\n","g = torch.arange(4, dtype=torch.int)\n"],"metadata":{"id":"SLZe8McEXKAM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Tensor attributes\n"],"metadata":{"id":"zsMEY1CVaJ0p"}},{"cell_type":"code","source":["print(\"Shape of the tensor:\", a.shape)\n","print(\"Shape of the tensor:\", c.shape)\n","\n","# Dtype - returns the data type of the tensor's elements\n","print(\"Data type of the tensor:\", a.dtype)\n","\n","# Device-specific operations\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","a_gpu = a.to(device)  # Moving tensor `a` to GPU (if available)\n","print(\"Tensor stored a  on:\", a.device)  # Output: cpu (default) or cuda:0 (if GPU is used)\n","print(\"Tensor stored a_gpu on:\", a_gpu.device)  # Output: cpu (default) or cuda:0 (if GPU is used)\n","\n","# Requires_grad - indicates whether the tensor is part of a computational graph and requires gradients\n","print(\"Does the tensor require gradients?:\", a.requires_grad)  # Output: False (default)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvjlZiJtaOe6","executionInfo":{"status":"ok","timestamp":1712521530763,"user_tz":-120,"elapsed":13,"user":{"displayName":"Bart?omiej Obrochta","userId":"06035287345701522738"}},"outputId":"af1f9747-b796-4cf0-90e5-0c13d879a813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the tensor: torch.Size([4])\n","Shape of the tensor: torch.Size([2, 5])\n","Data type of the tensor: torch.int64\n","Tensor stored a  on: cpu\n","Tensor stored a_gpu on: cuda:0\n","Does the tensor require gradients?: False\n"]}]},{"cell_type":"markdown","source":["## Tensor operations"],"metadata":{"id":"Xw3wcPYLag6v"}},{"cell_type":"code","source":["\n","tensor_a = torch.tensor([1, 2, 3])\n","tensor_b = torch.tensor([4, 5, 6])\n","\n","# Element-wise addition\n","sum_tensors = tensor_a + tensor_b\n","print(\"Element-wise addition:\", sum_tensors)  # Output: tensor([5, 7, 9])\n","\n","# Element-wise multiplication\n","product_tensors = tensor_a * tensor_b\n","print(\"Element-wise multiplication:\", product_tensors)  # Output: tensor([4, 10, 18])\n","\n","# Scalar multiplication\n","scalar_product = tensor_a * 2\n","print(\"Scalar multiplication:\", scalar_product)  # Output: tensor([2, 4, 6])\n","\n","# Slicing a tensor\n","sliced_tensor = tensor_b[1:]\n","print(\"Sliced tensor:\", sliced_tensor)  # Output: tensor([5, 6])\n","\n","# Computing the mean (requires floating-point dtype)\n","float_tensor = tensor_a.to(dtype=torch.float)\n","mean_value = float_tensor.mean()\n","print(\"Mean value:\", mean_value)  # Output: tensor(2.)\n","\n","# Transposing a matrix\n","matrix = torch.tensor([[1, 2], [3, 4]])\n","transposed_matrix = matrix.t()\n","print(\"Transposed matrix:\", transposed_matrix)  # Output: tensor([[1, 3], [2, 4]])\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGkdfNv0ajYx","executionInfo":{"status":"ok","timestamp":1712521530763,"user_tz":-120,"elapsed":12,"user":{"displayName":"Bart?omiej Obrochta","userId":"06035287345701522738"}},"outputId":"5451cdcb-60c3-4d6c-f814-0d3346f00067"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Element-wise addition: tensor([5, 7, 9])\n","Element-wise multiplication: tensor([ 4, 10, 18])\n","Scalar multiplication: tensor([2, 4, 6])\n","Sliced tensor: tensor([5, 6])\n","Mean value: tensor(2.)\n","Transposed matrix: tensor([[1, 3],\n","        [2, 4]])\n"]}]},{"cell_type":"markdown","source":["In PyTorch, both view and reshape methods are used to change the shape of a tensor. The view method requires the requested shape to be compatible with the original shape, and it returns a new tensor with the same data but a different shape. However, if the original tensor's layout in memory doesn't support the view, it will raise an error.\n","\n","On the other hand, reshape can handle these situations by potentially returning a tensor with a copied data if necessary to meet the shape requirements."],"metadata":{"id":"psdBJ1CPePld"}},{"cell_type":"code","source":["a_tensor = torch.arange(12)\n","view_tensor = a_tensor.view(3, 4)  # Changing the shape using view\n","reshape_tensor = a_tensor.reshape(4, 3)  # Changing the shape using reshape\n","\n","print(a_tensor)\n","print(\"\\n\")\n","print(view_tensor)\n","print(\"\\n\")\n","print(reshape_tensor)\n","\n","### view_tensor = a_tensor.view(4, 4)  # Changing the shape using view - results in error\n","###reshape_tensor = a_tensor.reshape(4, 4)  # Changing the shape using reshape - also results in an error\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c78llHO2eP92","executionInfo":{"status":"ok","timestamp":1712521530763,"user_tz":-120,"elapsed":8,"user":{"displayName":"Bart?omiej Obrochta","userId":"06035287345701522738"}},"outputId":"c0bb4452-0edc-4fae-e0ac-203edf650f9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n","\n","\n","tensor([[ 0,  1,  2,  3],\n","        [ 4,  5,  6,  7],\n","        [ 8,  9, 10, 11]])\n","\n","\n","tensor([[ 0,  1,  2],\n","        [ 3,  4,  5],\n","        [ 6,  7,  8],\n","        [ 9, 10, 11]])\n"]}]},{"cell_type":"markdown","source":["### Building Machine Learning models in PyTorch\n"],"metadata":{"id":"2WDvOvkGpLyP"}},{"cell_type":"markdown","source":["In PyTorch, creating neural network models involves defining a class that inherits from nn.Module, the base class for all neural network modules.\n","\n","This custom class, typically includes an __init__ method where layers and components of the model are instantiated.\n","\n","The forward method is then implemented to describe the forward propagation of data through the network. The forward method's definition is crucial as it dictates the data flow through the model, but notably, PyTorch automates the backward propagation (for computing gradients) during training, leveraging its dynamic computation graph.\n","\n","\n"],"metadata":{"id":"TrhHfnwhpOt6"}},{"cell_type":"code","source":["class MLPShallow(nn.Module):      #inheriting from nn.Module\n","  def __init__(self):\n","    super(MLPShallow, self).__init__()\n","\n","    # linear is our classical dense or fully-connected layer\n","    # Inside the __init__ method, we define the layers of the model as class attributes.\n","    # Each layer type (nn.Linear, nn.Conv2d, etc.) comes with its own parameters, like the number of input and output features.\n","    self.input_layer = nn.Linear(784, 256)\n","    self.hidden_layer1 = nn.Linear(256, 512)\n","    self.hidden_layer2 = nn.Linear(512, 512)\n","    self.hidden_layer3 = nn.Linear(512, 256)\n","    self.hidden_layer4 = nn.Linear(256, 256)\n","    self.hidden_layer5 = nn.Linear(256, 128)\n","    self.hidden_layer6 = nn.Linear(128, 64)\n","    self.output_layer = nn.Linear(64, 10)\n","\n","  #On top of nn.Linear PyTorch provides far more layeres we can choose for example:\n","  # Normalization Layers, Vision Layers, Padding Layers, Convolution Layers\n","  # implement a computational graph describing the data flow, here x is our data\n","  # the x will be activations - processed data but we keep the symbol - it represent the data flow.\n","  # note, that we define only the forward propagation of the signal, the backpropagation\n","  # will be performed automatically by the framework\n","\n","  def forward(self, x):\n","\n","  # Although not stored as class attributes, activation functions (F.relu, F.softmax, etc.)\n","  # are applied to the outputs of layers within the forward method.\n","\n","    x = F.leaky_relu(self.input_layer(x))     # F is functional from imports\n","    x = F.leaky_relu(self.hidden_layer1(x))\n","    x = F.leaky_relu(self.hidden_layer2(x))\n","    x = F.leaky_relu(self.hidden_layer3(x))\n","    x = F.leaky_relu(self.hidden_layer4(x))\n","    x = F.leaky_relu(self.hidden_layer5(x))\n","    x = F.leaky_relu(self.hidden_layer6(x))\n","\n","\n","    #This:\n","     # x = F.softmax(self.output_layer(x), dim=1)\n","     # return x\n","\n","    #is equal\n","\n","\n","    x = self.output_layer(x)\n","\n","    return x\n","\n","\n","# Create a loss function\n","\n","# CrossEntropyLoss will apply softmax internally\n","\n","model = MLPShallow()\n","\n","\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n"],"metadata":{"id":"Q8T3LkxxvV75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading data\n","\n"],"metadata":{"id":"Qki-zohlhxt6"}},{"cell_type":"markdown","source":["We'll use Fashion-MINST image classification dataset containing 60,000 examples and a test set of 10,000 examples.\n"],"metadata":{"id":"Jn4h5ELXry7A"}},{"cell_type":"code","source":["### Here we are describing how to handle data - chaining transofmrations\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5))])\n","\n","### Downloading data and aplying transformations\n","training_data = torchvision.datasets.MNIST(root=\"../data\", train=True, transform=transform, download=True)\n","test_data = torchvision.datasets.MNIST(root=\"../data\", train=False, transform=transform, download=True)\n","\n","\n","### Loading the data as well as specyfing the batch_size(It determines the number of images passed through the network in one forward/backward pass.),\n","### shuffle (Whether to shuffle the data at every epoch. It helps in reducing overfitting.)\n","### num_workers (How many subprocesses to use for data loading)\n","training_data_loader = torch.utils.data.DataLoader(training_data, batch_size=64, shuffle=True, num_workers=2)\n","test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, num_workers=2)"],"metadata":{"id":"SbyXsFvwsAQ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Training\n","\n","Compared to tensorflow - training in PyTorch is handled in a different way, as we are resposible for creating and optimizing the training loop\n"],"metadata":{"id":"r-MSalWLtMj1"}},{"cell_type":"code","source":["\n","# Training Loop\n","Epochs = 30\n","for epoch in range(Epochs):\n"," # Initialize variables to track training loss and accuracy\n","  training_loss = 0.0\n","  correct = 0\n","  total = 0\n","  for i, data in enumerate(training_data_loader, 0):\n","   # Unpack the batch of data; 'inputs' are the features, 'labels' are the target output\n","    inputs, labels = data\n","\n","    # Flatten the input images into vectors for MLP processing\n","    inputs = inputs.view(inputs.shape[0], -1)\n","\n","    # Clear previously calculated gradients before the forward pass\n","    optimizer.zero_grad()\n","\n","    # Perform the forward pass through the model\n","    outputs = model(inputs)\n","\n","    # The difference between the model's predictions (outputs) and the actual targets (labels)\n","    # is computed using a loss function. This loss guides the model's learning.\n","    loss = loss_function(outputs, labels)\n","\n","    # Calling loss.backward() computes the gradient of the loss with respect to each parameter.\n","    # These gradients are used to adjust the parameters in the direction that reduces the loss.\n","    loss.backward()\n","\n","    # The optimizer updates the model's parameters based on the gradients computed during backpropagation.\n","    # Different optimization algorithms (SGD, Adam, etc.) adjust the parameters in various ways.\n","    optimizer.step()\n","\n","    # Accumulate the loss for reporting. '.item()' extracts the loss's scalar value.\n","    training_loss += loss.item()\n","\n","    # Calculate the number of correctly predicted labels\n","    _, predicted = outputs.max(1)\n","    total += labels.size(0)\n","    correct += predicted.eq(labels).sum().item()\n","\n","    # Compute the average loss and accuracy over the current batch\n","    avg_loss = training_loss / (i + 1)\n","    avg_acc = 100. * correct / total\n","\n","  # Print the average loss and accuracy for the epoch\n","  print(f'Training Loss: {avg_loss:.3f} | Training acc: {avg_acc:.3f}', 'for epoch: ', epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4kCwb98tMTV","executionInfo":{"status":"ok","timestamp":1712522704129,"user_tz":-120,"elapsed":540705,"user":{"displayName":"Bart?omiej Obrochta","userId":"06035287345701522738"}},"outputId":"bc411707-613f-4080-b730-c6d8492ab1ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Loss: 2.300 | Training acc: 11.222 for epoch:  0\n","Training Loss: 1.658 | Training acc: 38.757 for epoch:  1\n","Training Loss: 0.477 | Training acc: 86.770 for epoch:  2\n","Training Loss: 0.260 | Training acc: 93.028 for epoch:  3\n","Training Loss: 0.192 | Training acc: 94.840 for epoch:  4\n","Training Loss: 0.152 | Training acc: 95.803 for epoch:  5\n","Training Loss: 0.123 | Training acc: 96.592 for epoch:  6\n","Training Loss: 0.103 | Training acc: 97.070 for epoch:  7\n","Training Loss: 0.089 | Training acc: 97.422 for epoch:  8\n","Training Loss: 0.078 | Training acc: 97.698 for epoch:  9\n","Training Loss: 0.063 | Training acc: 98.188 for epoch:  10\n","Training Loss: 0.060 | Training acc: 98.240 for epoch:  11\n","Training Loss: 0.054 | Training acc: 98.427 for epoch:  12\n","Training Loss: 0.045 | Training acc: 98.665 for epoch:  13\n","Training Loss: 0.043 | Training acc: 98.700 for epoch:  14\n","Training Loss: 0.037 | Training acc: 98.917 for epoch:  15\n","Training Loss: 0.034 | Training acc: 98.958 for epoch:  16\n","Training Loss: 0.031 | Training acc: 99.043 for epoch:  17\n","Training Loss: 0.029 | Training acc: 99.097 for epoch:  18\n","Training Loss: 0.024 | Training acc: 99.280 for epoch:  19\n","Training Loss: 0.024 | Training acc: 99.265 for epoch:  20\n","Training Loss: 0.021 | Training acc: 99.383 for epoch:  21\n","Training Loss: 0.019 | Training acc: 99.380 for epoch:  22\n","Training Loss: 0.019 | Training acc: 99.412 for epoch:  23\n","Training Loss: 0.018 | Training acc: 99.448 for epoch:  24\n","Training Loss: 0.016 | Training acc: 99.505 for epoch:  25\n","Training Loss: 0.016 | Training acc: 99.528 for epoch:  26\n","Training Loss: 0.014 | Training acc: 99.595 for epoch:  27\n","Training Loss: 0.009 | Training acc: 99.738 for epoch:  28\n","Training Loss: 0.009 | Training acc: 99.752 for epoch:  29\n"]}]},{"cell_type":"markdown","source":["### Evaluating performance"],"metadata":{"id":"wxZSao-7JBse"}},{"cell_type":"markdown","source":[" Evaluating the model outside the training loop is advantageous as it allows performance metrics to be calculated just once, specifically for the model at its peak performance. This streamlined approach not only ensures efficiency but also focuses on assessing the model's best iteration."],"metadata":{"id":"U1paExFPVjDI"}},{"cell_type":"code","source":["model.eval()\n","\n","# Initialize variables to track test loss and accuracy\n","test_loss = 0\n","correct = 0\n","\n","# No gradient calculations needed for inference, which saves memory and computations\n","with torch.no_grad():\n","\n","    # Iterate over all test data batches\n","    for i, (image, label) in enumerate(test_data_loader):\n","\n","        # Reshape images to match the input expected by the network (flatten the images)\n","        image = image.view(image.shape[0], -1)\n","\n","        # Forward pass: compute predicted outputs by passing images to the model\n","        output = model(image)\n","\n","        # Calculate the batch's loss using the negative log likelihood loss.\n","        # 'reduction=sum' calculates the sum of losses across all examples in the batch.\n","\n","        test_loss += F.nll_loss(output, label, reduction='sum').item()\n","\n","        # Get the index of the max log-probability (the predicted class label)\n","        pred = output.data.max(1, keepdim=True)[1]\n","\n","        # Count how many predictions match the true labels\n","        correct += pred.eq(label.data.view_as(pred)).sum()\n","\n","    # Calculate average loss over all test data\n","    test_loss /= len(test_data_loader.dataset)\n","\n","    # Print test set results including average loss and accuracy\n","\n","    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_data_loader.dataset), 100. * correct / len(test_data_loader.dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDVy3ctRC7oY","executionInfo":{"status":"ok","timestamp":1712524401996,"user_tz":-120,"elapsed":2446,"user":{"displayName":"Bart?omiej Obrochta","userId":"06035287345701522738"}},"outputId":"2dc47c9b-375f-4eb2-9686-461f9b61f038"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Avg. loss: -24.8135, Accuracy: 9804/10000 (98%)\n","\n"]}]},{"cell_type":"markdown","source":["###Summary\n","\n","We've found that the PyTorch library offers a robust and flexible approach, granting developers and researchers extensive control over their models. This level of freedom and the dynamic computation graph PyTorch employs significantly benefit complex model development and research, where intricate customizations and iterative adjustments are common. While the report primarily focuses on PyTorch, it's worth noting that frameworks like TensorFlow can be advantageous for rapid prototyping and simpler networks, thanks to their streamlined workflows and comprehensive toolsets. Ultimately, PyTorch stands out in scenarios that demand deep model customization and hands-on control."],"metadata":{"id":"knAP39XAP97U"}}]}